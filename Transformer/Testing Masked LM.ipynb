{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-02T01:35:06.702867Z","iopub.status.busy":"2024-08-02T01:35:06.702456Z","iopub.status.idle":"2024-08-02T01:35:29.770755Z","shell.execute_reply":"2024-08-02T01:35:29.769427Z","shell.execute_reply.started":"2024-08-02T01:35:06.702833Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-08-02 01:35:15.978511: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-08-02 01:35:15.978673: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-08-02 01:35:16.174940: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"name":"stdout","output_type":"stream","text":["/kaggle/input/gpt-34/pytorch/default/1/mlm_model.pth\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","from transformers import AutoTokenizer, DataCollatorForLanguageModeling\n","from datasets import load_dataset, DatasetDict, load_from_disk\n","import torch\n","from torch import tensor, einsum\n","from torch.nn import Module, Sequential, Softmax, GELU, Linear, Dropout, LayerNorm, Embedding, ModuleList, DataParallel\n","import math\n","import numpy as np\n","from collections import OrderedDict\n","\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# The Transformer Architecture and Encoder Definitions\n","#### Training in Kaggle, Did not import the python files"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T01:35:29.773819Z","iopub.status.busy":"2024-08-02T01:35:29.773044Z","iopub.status.idle":"2024-08-02T01:35:29.807901Z","shell.execute_reply":"2024-08-02T01:35:29.806621Z","shell.execute_reply.started":"2024-08-02T01:35:29.773774Z"},"trusted":true},"outputs":[],"source":["class Attention(Module):\n","    def __init__(self, embedding_dim, num_heads, *args, **kwargs) -> None:\n","        assert embedding_dim % num_heads == 0, \"The embedding dimension must be divisible by the number of heads\"\n","        super().__init__(*args, **kwargs)\n","        self.embed_dim = embedding_dim\n","        self.n_head = num_heads\n","        self.head_dim = embedding_dim // num_heads\n","        \n","        self.queryLinear = Linear(self.head_dim, self.head_dim, bias=False)\n","        self.keyLinear = Linear(self.head_dim, self.head_dim, bias=False)\n","        self.valueLinear = Linear(self.head_dim, self.head_dim, bias=False)\n","        \n","        self.fc = Linear(self.head_dim, self.embed_dim)\n","        \n","        self.sft = Softmax(dim=-1)\n","        \n","    def forward(self, queries, keys, values, mask=None):\n","        # first reshape the tensors to be divided into heads\n","        qs, ks, vs = queries.shape, keys.shape, values.shape\n","        assert qs[0] == ks[0] and ks[0] == vs[0], \"The batch size should be the same across all passed tensors\"\n","        assert ks[1] == vs[1], \"The sequence length should be the same across all the keys and the values\"\n","        assert qs[2] == self.embed_dim and ks[2] == self.embed_dim and vs[2] == self.embed_dim, f\"The embedding size should be equal to {self.embed_dim} across all tensors\"\n","        \n","        queries = queries.reshape((qs[0], qs[1], self.n_head, self.head_dim))\n","        keys = keys.reshape((ks[0], ks[1], self.n_head, self.head_dim))\n","        values = values.reshape((vs[0], vs[1], self.n_head, self.head_dim))\n","        \n","        queries = self.queryLinear(queries)\n","        keys = self.keyLinear(keys)\n","        values = self.valueLinear(values)\n","        \n","        # b the batch size\n","        # q, k the lengths of the sequences\n","        # n the number of heads\n","        # h the head dim\n","        product = einsum(\"bqnh,bknh->bnqk\", queries, keys)\n","        \n","        if mask is not None:\n","            expanded_mask = mask.unsqueeze(1).unsqueeze(1).expand(-1, self.n_head, qs[1], -1)\n","            product = product.masked_fill(expanded_mask == 0, -1e4)\n","        \n","        insight = self.sft(product / math.sqrt(self.embed_dim))\n","        \n","        # b the batch size\n","        # q, k, v the lengths of the sequences (k == v)\n","        # n the number of heads\n","        # h the head dim\n","        output = einsum(\"bnqk,bknh->bqnh\", insight, values)\n","        \n","        return output.reshape((qs[0], qs[1], self.embed_dim))\n","    \n","\n","\n","class TransformerBlock(Module):\n","    def __init__(self, embedding_dim, num_heads, ffd_expansion = 4, dropout=0.2, *args, **kwargs) -> None:\n","        super().__init__(*args, **kwargs)\n","        self.attention = Attention(embedding_dim, num_heads)\n","        self.norm1 = LayerNorm(embedding_dim)\n","        self.ffd = Sequential(\n","            Linear(embedding_dim, embedding_dim * ffd_expansion),\n","            GELU(),\n","            Linear(embedding_dim*ffd_expansion, embedding_dim)\n","        )\n","        self.norm2 = LayerNorm(embedding_dim)\n","        self.dropout = Dropout(dropout)\n","        \n","    \n","    def forward(self, input, mask=None):\n","        attention = self.attention(input, input, input, mask)\n","        output1 = self.dropout(self.norm1(attention + input))\n","        output2 = self.ffd(output1) + output1\n","        output = self.dropout(self.norm2(output2))\n","        return output\n","    \n","def positionalEncoding(seq_len, embed_dim, n = 10000):\n","    assert embed_dim%2 == 0, \"The embedding dimension must be even\"\n","    \n","    pos = seq_len\n","    d = embed_dim\n","    \n","    positions = torch.arange(0, pos).unsqueeze(1)\n","    powers = torch.pow(n, torch.arange(0, d//2)/d)\n","    embeddings = torch.zeros((pos, d))\n","    \n","    embed_in = positions / powers\n","    \n","    embeddings[:, 0::2] = torch.sin(embed_in)\n","    embeddings[:, 1::2] = torch.cos(embed_in)\n","    \n","    \n","    return embeddings\n","\n","\n","\n","\n","class Encoder(Module):\n","    def __init__(self, vocab_size, embedding_dim, n_layers, n_heads, max_length, ffd = 4, dropout = 0.2, device = 'cpu', *args, **kwargs) -> None:\n","        super().__init__(*args, **kwargs)\n","        self.embedding_dim = embedding_dim\n","        self.n_layers = n_layers\n","        self.n_heads = n_heads\n","        self.max_length = max_length\n","        self.vocab_size = vocab_size\n","        self.embedding = Embedding(vocab_size, embedding_dim)\n","        self.positionalEncoding = positionalEncoding(max_length, embedding_dim)\n","        self.layers = ModuleList(\n","            [TransformerBlock(embedding_dim, n_heads, ffd, dropout) for _ in range(n_layers)]\n","        )\n","        self.dropout = Dropout(dropout)\n","        self.head = Linear(embedding_dim, vocab_size)\n","        \n","    def forward(self, x, mask=None):\n","        output = self.dropout(self.embedding(x) + self.positionalEncoding.unsqueeze(dim=0).expand(x.shape[0], self.max_length, self.embedding_dim).to(x.device))\n","        \n","        for layer in self.layers:\n","            output = layer(output, mask)\n","            \n","        return self.head(output)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T01:35:29.850027Z","iopub.status.busy":"2024-08-02T01:35:29.849665Z","iopub.status.idle":"2024-08-02T01:35:31.652612Z","shell.execute_reply":"2024-08-02T01:35:31.651367Z","shell.execute_reply.started":"2024-08-02T01:35:29.849983Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a4dd0cd9a324f0eb0a3b5627991fdf2","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c10c1884daaa4ecc9203cb2d36b45c8a","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"142ab019a74b4a939c116c54bacb3ef9","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b48fcf9f91b444eb096449a61e62362","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Fast Tokenizer: True\n"]}],"source":["num_proc = os.cpu_count()\n","\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', use_fast=True)\n","print(f\"Fast Tokenizer: {tokenizer.is_fast}\")\n","\n","max_length = 64"]},{"cell_type":"markdown","metadata":{},"source":["# Instantiate the model"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T01:35:31.654949Z","iopub.status.busy":"2024-08-02T01:35:31.654509Z","iopub.status.idle":"2024-08-02T01:35:35.056517Z","shell.execute_reply":"2024-08-02T01:35:35.055405Z","shell.execute_reply.started":"2024-08-02T01:35:31.654908Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]},{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["vocab_size = tokenizer.vocab_size\n","embed_size = 768\n","num_layers = 6\n","num_heads = 8\n","dropout = 0.1\n","expansion = 4\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(device)\n","model = Encoder(vocab_size, embed_size, num_layers, num_heads, max_length, expansion, dropout, device).to(device)\n","\n","# Create a new ordered dict to store the new state dict without 'module.' prefix\n","def remove_module_prefix(state_dict):\n","    new_state_dict = OrderedDict()\n","    for k, v in state_dict.items():\n","        if k.startswith('module.'):\n","            new_state_dict[k[7:]] = v\n","        else:\n","            new_state_dict[k] = v\n","    return new_state_dict\n","\n","state_dict = remove_module_prefix(torch.load(\"/kaggle/input/gpt-34/pytorch/default/1/mlm_model.pth\", map_location='cpu'))\n","model.load_state_dict(state_dict)"]},{"cell_type":"markdown","metadata":{},"source":["# Utility for Masking Random Words in a sentence"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T01:35:35.058359Z","iopub.status.busy":"2024-08-02T01:35:35.057957Z","iopub.status.idle":"2024-08-02T01:35:35.070193Z","shell.execute_reply":"2024-08-02T01:35:35.068815Z","shell.execute_reply.started":"2024-08-02T01:35:35.058328Z"},"trusted":true},"outputs":[],"source":["from random import randint\n","from collections import OrderedDict\n","\n","def mask_random_word(tokenizer, sentences):\n","    masked_sentences = []\n","\n","    for sentence in sentences:\n","        encoding = tokenizer(sentence, return_tensors=\"pt\", truncation=True, return_special_tokens_mask=True, padding=\"max_length\", max_length=max_length)\n","        if len(encoding[\"input_ids\"]) == 0:\n","            continue\n","        \n","        words = encoding.word_ids()\n","        i = len(words) - 1\n","        while i >= 0:\n","            if words[i] != None:\n","                break\n","            i -= 1\n","        r = i\n","        while True:\n","            r = randint(1, i)\n","            if words[r] is not None:\n","                break\n","        \n","        i = words[r]\n","        sen = {}\n","        sen[\"word_id\"] = i\n","        start, end = encoding.word_to_chars(i)\n","        sen[\"word\"] = sentence[start:end]\n","        sen[\"original\"] = sentence\n","        for idx, k in enumerate(words):\n","            if k == i:\n","                encoding[\"input_ids\"][0][idx] = tokenizer.mask_token_id\n","        sen[\"masked\"] = sentence[:start] + tokenizer.mask_token + sentence[end:]\n","        sen[\"encoding\"] = encoding\n","        \n","        masked_sentences.append(sen)\n","    \n","    return masked_sentences\n"]},{"cell_type":"markdown","metadata":{},"source":["# Testing the Utility against Transformers' Data Collator for MLM"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T01:35:35.071864Z","iopub.status.busy":"2024-08-02T01:35:35.071542Z","iopub.status.idle":"2024-08-02T01:35:35.103596Z","shell.execute_reply":"2024-08-02T01:35:35.102588Z","shell.execute_reply.started":"2024-08-02T01:35:35.071836Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["On a sunny afternoon, the children decided to play in the park, enjoying the fresh air and warm sunshine.\n","On a sunny afternoon, the children decided to play in the park, enjoying the fresh air and warm [MASK].\n","sunshine\n","20\n","tensor([[  101,  2006,  1037, 11559,  5027,  1010,  1996,  2336,  2787,  2000,\n","          2377,  1999,  1996,  2380,  1010,  9107,  1996,  4840,  2250,  1998,\n","          4010,   103,  1012,   102,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0]])\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"]}],"source":["f = mask_random_word(tokenizer, [\"On a sunny afternoon, the children decided to play in the park, enjoying the fresh air and warm sunshine.\"])\n","for i in f:\n","    print(i[\"original\"])\n","    print(i[\"masked\"])\n","    print(i[\"word\"])\n","    print(i[\"word_id\"])\n","    print(i[\"encoding\"][\"input_ids\"])\n","    print(i[\"encoding\"][\"attention_mask\"])    "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T01:35:35.105776Z","iopub.status.busy":"2024-08-02T01:35:35.105102Z","iopub.status.idle":"2024-08-02T01:35:35.143611Z","shell.execute_reply":"2024-08-02T01:35:35.142500Z","shell.execute_reply.started":"2024-08-02T01:35:35.105744Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': tensor([[[  101,  2006,  1037, 11559,  5027,  1010,  1996,  2336,  2787,  2000,\n","           2377,  1999,  1996,  2380,  1010,  9107,  1996,  4840,  2250,  1998,\n","           4010,  9609,  1012,   102,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","              0,     0,     0,     0]]]), 'token_type_ids': tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]), 'attention_mask': tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","          1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]), 'labels': tensor([[[-100, -100, -100, -100, -100, -100, -100, -100, 2787, -100, -100,\n","          -100, -100, -100, 1010, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n","          -100, -100, -100, -100, -100, -100, -100, -100, -100]]])}\n"]}],"source":["from transformers import DataCollatorForLanguageModeling\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer,\n","    mlm=True,\n","    mlm_probability=0.1\n",")\n","\n","sentence = [\"On a sunny afternoon, the children decided to play in the park, enjoying the fresh air and warm sunshine.\"]\n","\n","encoding = tokenizer(sentence, return_tensors=\"pt\", truncation=True, return_special_tokens_mask=True, padding=\"max_length\", max_length=max_length)\n","\n","print(data_collator([encoding]))"]},{"cell_type":"markdown","metadata":{},"source":["# Function to Predict Masked Words"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T01:45:53.551610Z","iopub.status.busy":"2024-08-02T01:45:53.550837Z","iopub.status.idle":"2024-08-02T01:45:53.560664Z","shell.execute_reply":"2024-08-02T01:45:53.559424Z","shell.execute_reply.started":"2024-08-02T01:45:53.551574Z"},"trusted":true},"outputs":[],"source":["def predict_masked_words(model, tokenizer, masked_sentences):\n","    model.eval()\n","    predicted_sentences = []\n","\n","    for masked_tokens in masked_sentences:\n","        # Convert tokens to input IDs\n","        input_ids = masked_tokens[\"encoding\"][\"input_ids\"]\n","        mask = masked_tokens[\"encoding\"][\"attention_mask\"]\n","        \n","        # Get predictions\n","        with torch.no_grad():\n","            outputs = model(input_ids, mask)\n","        \n","        # Get the predicted tokens\n","        predicted_ids = torch.argmax(outputs, dim=-1).squeeze()\n","        predicted_tokens = tokenizer.decode(predicted_ids[input_ids[0] == tokenizer.mask_token_id])\n","        \n","        print(f\"Original : {masked_tokens['original']}\")\n","        print(f'Masked : {masked_tokens[\"masked\"]}')\n","        print(f\"Predicted Word : {predicted_tokens}\\n\")\n","    "]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T01:45:53.577166Z","iopub.status.busy":"2024-08-02T01:45:53.576682Z","iopub.status.idle":"2024-08-02T01:45:53.591582Z","shell.execute_reply":"2024-08-02T01:45:53.590127Z","shell.execute_reply.started":"2024-08-02T01:45:53.577126Z"},"trusted":true},"outputs":[],"source":["sentences = [\n","    \"The quick brown fox jumps over the lazy dog, while the dog continues to sleep without a care in the world.\",\n","    \"On a sunny afternoon, the children decided to play in the park, enjoying the fresh air and warm sunshine.\",\n","    \"The artist spent hours painting the beautiful landscape, capturing every detail with precise brushstrokes and vibrant colors.\",\n","    \"After a long day at work, Sarah enjoyed relaxing with a good book and a cup of hot tea.\",\n","    \"The chef prepared a delicious three-course meal, using fresh ingredients from the local farmers' market.\",\n","    \"During the summer vacation, the family traveled to the mountains, where they hiked, fished, and enjoyed nature.\",\n","    \"The teacher explained the complex math problem, ensuring that every student understood the steps required to solve it.\",\n","    \"Every morning, John goes for a jog around the neighborhood, enjoying the peacefulness before the hustle and bustle begins.\",\n","    \"The company announced its plans to expand internationally, bringing its innovative products to new markets around the world.\",\n","    \"At the museum, visitors marveled at the ancient artifacts, learning about the history and culture of civilizations long gone.\",\n","    \"The new smartphone boasts a variety of features, including a high-resolution camera, long battery life, and fast processing speed.\",\n","    \"During the concert, the band played their greatest hits, energizing the crowd and creating an unforgettable experience.\",\n","    \"The scientist conducted experiments to test the hypothesis, meticulously recording data and analyzing the results.\",\n","    \"On weekends, Maria loves to bake cookies and cakes, sharing her delicious creations with friends and family.\",\n","    \"The small town held an annual festival, featuring local food vendors, live music, and various fun activities for all ages.\",\n","    \"With determination and hard work, Emily managed to save enough money to buy her first car.\",\n","    \"The novel's plot twists and turns kept readers on the edge of their seats, eagerly turning pages to see what happens next.\",\n","    \"At the beach, children built sandcastles, collected seashells, and played in the gentle waves.\",\n","    \"The volunteer organization worked tirelessly to provide aid and support to communities affected by natural disasters.\",\n","    \"The sports team trained rigorously, aiming to improve their skills and achieve victory in the upcoming championship.\",\n","    \"In the early morning hours, the fisherman set out on his boat, hoping for a bountiful catch.\",\n","    \"The new park features walking trails, playgrounds, and picnic areas, making it a popular spot for families.\",\n","    \"With a clear sky and mild temperatures, it was the perfect day for a leisurely bike ride through the countryside.\",\n","    \"The movie's stunning visual effects and gripping storyline captivated audiences, making it a box office hit.\",\n","    \"During the gardening season, the community garden flourished, with residents planting and harvesting various fruits and vegetables.\",\n","    \"The engineer designed a revolutionary new product, aiming to solve common problems with innovative technology.\",\n","    \"On a chilly evening, the family gathered around the fireplace, sharing stories and enjoying hot cocoa.\",\n","    \"The book club met monthly, discussing their latest read and sharing insights and perspectives on the story.\",\n","    \"The startup company quickly gained popularity, attracting investors and customers with its unique approach and cutting-edge products.\",\n","    \"At the zoo, visitors observed exotic animals from around the world, learning about their habitats and behaviors.\"\n","]\n"]},{"cell_type":"markdown","metadata":{},"source":["# Results"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T01:45:53.594880Z","iopub.status.busy":"2024-08-02T01:45:53.593742Z","iopub.status.idle":"2024-08-02T01:45:56.550490Z","shell.execute_reply":"2024-08-02T01:45:56.549360Z","shell.execute_reply.started":"2024-08-02T01:45:53.594839Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Original : The quick brown fox jumps over the lazy dog, while the dog continues to sleep without a care in the world.\n","Masked : The quick brown fox jumps over the lazy dog, while the [MASK] continues to sleep without a care in the world.\n","Predicted Word : man\n","\n","Original : On a sunny afternoon, the children decided to play in the park, enjoying the fresh air and warm sunshine.\n","Masked : On a sunny afternoon, [MASK] children decided to play in the park, enjoying the fresh air and warm sunshine.\n","Predicted Word : the\n","\n","Original : The artist spent hours painting the beautiful landscape, capturing every detail with precise brushstrokes and vibrant colors.\n","Masked : The artist spent hours painting the beautiful landscape, capturing every detail with precise brushstrokes and [MASK] colors.\n","Predicted Word : the\n","\n","Original : After a long day at work, Sarah enjoyed relaxing with a good book and a cup of hot tea.\n","Masked : After a long day [MASK] work, Sarah enjoyed relaxing with a good book and a cup of hot tea.\n","Predicted Word : of\n","\n","Original : The chef prepared a delicious three-course meal, using fresh ingredients from the local farmers' market.\n","Masked : The chef prepared a delicious three-course meal, [MASK] fresh ingredients from the local farmers' market.\n","Predicted Word : a\n","\n","Original : During the summer vacation, the family traveled to the mountains, where they hiked, fished, and enjoyed nature.\n","Masked : During the summer vacation, the family traveled to the mountains, where they hiked, fished, and enjoyed [MASK].\n","Predicted Word : it\n","\n","Original : The teacher explained the complex math problem, ensuring that every student understood the steps required to solve it.\n","Masked : The [MASK] explained the complex math problem, ensuring that every student understood the steps required to solve it.\n","Predicted Word : man\n","\n","Original : Every morning, John goes for a jog around the neighborhood, enjoying the peacefulness before the hustle and bustle begins.\n","Masked : Every morning[MASK] John goes for a jog around the neighborhood, enjoying the peacefulness before the hustle and bustle begins.\n","Predicted Word : ,\n","\n","Original : The company announced its plans to expand internationally, bringing its innovative products to new markets around the world.\n","Masked : The company announced its plans to expand [MASK], bringing its innovative products to new markets around the world.\n","Predicted Word : it\n","\n","Original : At the museum, visitors marveled at the ancient artifacts, learning about the history and culture of civilizations long gone.\n","Masked : At the museum, visitors marveled at the ancient artifacts, learning [MASK] the history and culture of civilizations long gone.\n","Predicted Word : by\n","\n","Original : The new smartphone boasts a variety of features, including a high-resolution camera, long battery life, and fast processing speed.\n","Masked : The new smartphone boasts a variety [MASK] features, including a high-resolution camera, long battery life, and fast processing speed.\n","Predicted Word : of\n","\n","Original : During the concert, the band played their greatest hits, energizing the crowd and creating an unforgettable experience.\n","Masked : During the concert, the band played their greatest hits, energizing the crowd and [MASK] an unforgettable experience.\n","Predicted Word : made\n","\n","Original : The scientist conducted experiments to test the hypothesis, meticulously recording data and analyzing the results.\n","Masked : The scientist conducted experiments to test the hypothesis, [MASK] recording data and analyzing the results.\n","Predicted Word : and the the\n","\n","Original : On weekends, Maria loves to bake cookies and cakes, sharing her delicious creations with friends and family.\n","Masked : On weekends, Maria loves to bake cookies and cakes[MASK] sharing her delicious creations with friends and family.\n","Predicted Word : ,\n","\n","Original : The small town held an annual festival, featuring local food vendors, live music, and various fun activities for all ages.\n","Masked : The small town held an annual festival, featuring [MASK] food vendors, live music, and various fun activities for all ages.\n","Predicted Word : ,\n","\n","Original : With determination and hard work, Emily managed to save enough money to buy her first car.\n","Masked : With determination and hard work, Emily managed to save enough money to buy her [MASK] car.\n","Predicted Word : the\n","\n","Original : The novel's plot twists and turns kept readers on the edge of their seats, eagerly turning pages to see what happens next.\n","Masked : The novel's plot twists and turns kept readers on the edge of their seats, eagerly turning pages to see what happens [MASK].\n","Predicted Word : next\n","\n","Original : At the beach, children built sandcastles, collected seashells, and played in the gentle waves.\n","Masked : At the beach, children built sandcastles, collected [MASK], and played in the gentle waves.\n","Predicted Word : , thes\n","\n","Original : The volunteer organization worked tirelessly to provide aid and support to communities affected by natural disasters.\n","Masked : The volunteer organization worked tirelessly to provide aid and support to communities [MASK] by natural disasters.\n","Predicted Word : them\n","\n","Original : The sports team trained rigorously, aiming to improve their skills and achieve victory in the upcoming championship.\n","Masked : The sports team trained rigorously, aiming [MASK] improve their skills and achieve victory in the upcoming championship.\n","Predicted Word : to\n","\n","Original : In the early morning hours, the fisherman set out on his boat, hoping for a bountiful catch.\n","Masked : In the early [MASK] hours, the fisherman set out on his boat, hoping for a bountiful catch.\n","Predicted Word : few\n","\n","Original : The new park features walking trails, playgrounds, and picnic areas, making it a popular spot for families.\n","Masked : The new park features walking trails, playgrounds, and picnic areas, making it a [MASK] spot for families.\n","Predicted Word : small\n","\n","Original : With a clear sky and mild temperatures, it was the perfect day for a leisurely bike ride through the countryside.\n","Masked : With a clear sky and mild temperatures, it was [MASK] perfect day for a leisurely bike ride through the countryside.\n","Predicted Word : a\n","\n","Original : The movie's stunning visual effects and gripping storyline captivated audiences, making it a box office hit.\n","Masked : [MASK] movie's stunning visual effects and gripping storyline captivated audiences, making it a box office hit.\n","Predicted Word : the\n","\n","Original : During the gardening season, the community garden flourished, with residents planting and harvesting various fruits and vegetables.\n","Masked : During the gardening season, [MASK] community garden flourished, with residents planting and harvesting various fruits and vegetables.\n","Predicted Word : the\n","\n","Original : The engineer designed a revolutionary new product, aiming to solve common problems with innovative technology.\n","Masked : The engineer [MASK] a revolutionary new product, aiming to solve common problems with innovative technology.\n","Predicted Word : was\n","\n","Original : On a chilly evening, the family gathered around the fireplace, sharing stories and enjoying hot cocoa.\n","Masked : On a chilly evening, the family gathered around the fireplace, [MASK] stories and enjoying hot cocoa.\n","Predicted Word : the\n","\n","Original : The book club met monthly, discussing their latest read and sharing insights and perspectives on the story.\n","Masked : The book club met monthly, discussing their latest read and sharing insights and perspectives [MASK] the story.\n","Predicted Word : of\n","\n","Original : The startup company quickly gained popularity, attracting investors and customers with its unique approach and cutting-edge products.\n","Masked : The startup company quickly gained popularity, attracting investors and customers with its unique approach and cutting-edge [MASK].\n","Predicted Word : ##s\n","\n","Original : At the zoo, visitors observed exotic animals from around the world, learning about their habitats and behaviors.\n","Masked : At the zoo, visitors observed exotic animals from [MASK] the world, learning about their habitats and behaviors.\n","Predicted Word : all\n","\n"]}],"source":["predict_masked_words(model, tokenizer, mask_random_word(tokenizer, sentences))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"isSourceIdPinned":true,"modelId":97986,"modelInstanceId":73103,"sourceId":87037,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
